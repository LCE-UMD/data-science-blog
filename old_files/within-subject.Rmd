---
title: "11-Bootstrapping"
output: html_document
---

# Within- and between-participant variability

Data vary for lots of reasons. But in human and animal research, there are two forms of variability that are inherently distinct: **within-participant** and **between-participant**. Let's explore some of the reasons to keep track of where variability comes from.

(Before that let's pause for a second to think why keeping track of these might appear to not matter. Suppose you have a group of observations $A$ (of any kind) and a separate group of observartions B. So if you take the average of A, $\bar{x}_A$, and the average of $B$, $\bar{x}_B$, the overall average $\bar{x}_{A,B}$ is the same as $\frac{1}{2}(
\bar{x}_A + \bar{x}_B)$. This is simply because the "average of the averages" is the same as the "average of everything individually," a convenient property of things that combine *linearly*.)

Back to *within-participant* and *between-participant* variability. 

Suppose the observations $A$ and $B$ come from two separate **sets of participants**. We could see how different the "typical" responses to $A$ and $B$ are by calculating $\bar{x}_A-\bar{x}_B$. 

Now suppose you have multiple observations $A$ and $B$ from the **same participant**, and that you have, as typical, multiple participants. In this case, you have a richer scenario because each participant has multiple data points for $A$ and multiple data points for $B$. You capitalize upon that nested structure in the following way.

If you summarize the typical response to manipulation $A$ as $\bar{x}_A$ and to manipulation $B$ as $\bar{x}_B$ for subject $1$, then $\bar{x}_A-\bar{x}_B$ represents the difference score **within** that subject. You can do the same for all other participants. Now, if you are interested in how $A$ and $B$ differ, you can look at *difference scores* defined **within participants** and see how they are distributed **across participants**. 

What this does for you is to remove the *subject effect*, and allows you to focus on the *treatment effect A vs. B*. So if subject $1$ is, for example, a "fast responder"" (say fast reaction times in general), the fact that $B$ is associated with a larger mean  than $A$ is not masked by across-individual variability in baseline responding.

The figure below illustrates the situation. There's a consistent *treatment effect* from $A$ to $B$ within subject, but that will only be clear if you eliminate across-participant variability.

```{r out.width = "100%", echo=FALSE, fig.cap="Within-subject differences studied across participants. $A$ and $B$ represent the two conditions of interest. The bottom gray line indicates the range of responding from $150$ to $650$ (say, reaction times in milliseconds), and arbitrary low, medium, and high respoding zones (L, M, and H). The small purple lines are individual trials, and the thicker line is the mean for that condition."}
knitr::include_graphics("within-subject.png")
```

**Conclusion**: When you have within-participant data think about the object of interest as **difference scores**. You have a much better way to estimate differences, so forget about $A$ and $B$ individually and think of $A-B$.







